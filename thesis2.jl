if something(findfirst(isequal("./"),LOAD_PATH),0) == 0
    push!(LOAD_PATH, "./")
end
using Distributed
using Distributions
using ForwardDiff
using JuMP
using NLopt
using GR
using DataFrames
using MultivariateStats
using Flux
using DelimitedFiles
using Statistics
using Printf
using Parameters
using Simulator

#Basis functions
œï(x) = [1,
        v(x),
        s(x),
        p(x),
        q(x)+h(x),
        1e-4*(q(x)+h(x))^2,
        1e-4*(q(x)^2 + h(x)^2)]#6.25e-8
        #1e-16*v(x)^3,
        #1e-10*(q(x)+h(x))^3,

œï(X::Array{Array{Float64,1},1}) = permutedims(Flux.batch(œï.(X)))

#Function approximations
V(Œ∏,x) =  sum(Œ∏ .* œï(x))
Œ¥·µÉ(Œ∏,x) = sum(Œ∏ .* œï(x))
Œ¥·µá(Œ∏,x) = sum(Œ∏ .* œï(x))
Œæ(Œ∏,x) =  sum(Œ∏ .* œï(x))

function get_param(X)
    x = X[1:5]
    Œ∏ = X[6:length(X)]
    x,Œ∏
end

function get_x(X)
    X[1:5]
end

#Value funcion as function of one master argument
#with both the state x and the parameters Œ∏·µõ
function V(X)
    x,Œ∏ = get_param(X)
    V(Œ∏,x)
end

#Reward function partial derivatives
‚àáR(x) = ForwardDiff.gradient(R,x)
‚àá¬≤R(x) = ForwardDiff.hessian(R,x)
‚àÇRy(x) = ‚àáR(x)[1]
‚àÇRs(x) = ‚àáR(x)[2]
‚àÇRp(x) = ‚àáR(x)[3]
‚àÇRq(x) = ‚àáR(x)[4]
‚àÇRh(x) = ‚àáR(x)[5]
‚àÇ‚àÇRss(x) = ‚àá¬≤R(x)[2,2]
‚àÇ‚àÇRpp(x) = ‚àá¬≤R(x)[3,3]
‚àÇ‚àÇRsp(x) = ‚àá¬≤R(x)[2,3]

#Value function partial derivatives
‚àáV(Œ∏,x) = ForwardDiff.gradient(V,[x;Œ∏])
‚àáVx(Œ∏,x) = ‚àáV(Œ∏,x)[1:5]
‚àáVŒ∏(Œ∏,x) = ‚àáV(Œ∏,x)[6:end]
‚àá¬≤V(Œ∏,x) = ForwardDiff.hessian(V,[x;Œ∏])
‚àá¬≤Vx(Œ∏,x) = ‚àá¬≤V(Œ∏,x)[1:5,1:5]
‚àÇVy(Œ∏,x) = ‚àáV(Œ∏,x)[1]
‚àÇVs(Œ∏,x) = ‚àáV(Œ∏,x)[2]
‚àÇVp(Œ∏,x) = ‚àáV(Œ∏,x)[3]
‚àÇVq(Œ∏,x) = ‚àáV(Œ∏,x)[4]
‚àÇVh(Œ∏,x) = ‚àáV(Œ∏,x)[5]
‚àÇ‚àÇVss(Œ∏,x) = ‚àá¬≤V(Œ∏,x)[2,2]
‚àÇ‚àÇVpp(Œ∏,x) = ‚àá¬≤V(Œ∏,x)[3,3]
‚àÇ‚àÇVsp(Œ∏,x) = ‚àá¬≤V(Œ∏,x)[2,3]

#Value ingredients
Œî·µÉ(x,Œ¥·µÉ,r·µÉ) = [y(x) + (r·µÉ>=Œ¥·µÉ ? s(x)*(1+Œ¥·µÉ) : 0), s(x) + s(x)*r·µÉ, p(x) + s(x)*r·µÉ, q(x) + (r·µÉ>=Œ¥·µÉ ? -1 : 0), h(x)]
Œî·µá(x,Œ¥·µá,r·µá) = [y(x) + (r·µá>=Œ¥·µá ? -s(x)*(1-Œ¥·µá) : 0), s(x) - s(x)*r·µá, p(x) - s(x)*r·µá, q(x) + (r·µá>=Œ¥·µá ?  1 : 0), h(x)]
Œî·µÉV(Œ∏,x,Œ¥·µÉ,r·µÉ) = V(Œ∏,Œî·µÉ(x,Œ¥·µÉ,r·µÉ)) - V(Œ∏,x)
Œî·µáV(Œ∏,x,Œ¥·µá,r·µá) = V(Œ∏,Œî·µá(x,Œ¥·µá,r·µá)) - V(Œ∏,x)
Œî·µÉ·µñV(Œ∏,x,r·µñ) = cheap(x) ? V(Œ∏,[y(x),s(x),p(x)+s(x)*r·µñ,q(x),h(x)]) - V(Œ∏,x) : 0
Œî·µá·µñV(Œ∏,x,r·µñ) = rich(x) ? V(Œ∏,[y(x),s(x),p(x)-s(x)*r·µñ,q(x),h(x)]) - V(Œ∏,x) : 0
EŒî·µÉV(Œ∏,x,Œ¥·µÉ) = mean([Œî·µÉV(Œ∏,x,Œ¥·µÉ,r) for r in r·µÉ(x)])
EŒî·µáV(Œ∏,x,Œ¥·µá) = mean([Œî·µáV(Œ∏,x,Œ¥·µá,r) for r in r·µá(x)])
EŒî·µÉ·µñV(Œ∏,x) = mean([Œî·µÉ·µñV(Œ∏,x,r) for r in r·µÉ(x)])
EŒî·µá·µñV(Œ∏,x) = mean([Œî·µá·µñV(Œ∏,x,r) for r in r·µá(x)])

#Reward ingredients
Œî·µÉR(x,Œ¥·µÉ,r·µÉ) = R(Œî·µÉ(x,Œ¥·µÉ,r·µÉ)) - R(x)
Œî·µáR(x,Œ¥·µá,r·µá) = R(Œî·µá(x,Œ¥·µá,r·µá)) - R(x)
Œî·µÉ·µñR(x,r·µñ) = cheap(x) ? R([y(x),s(x),p(x)+s(x)*r·µñ,q(x),h(x)]) - R(x) : 0
Œî·µá·µñR(x,r·µñ) = rich(x) ? R([y(x),s(x),p(x)-s(x)*r·µñ,q(x),h(x)]) - R(x) : 0
EŒî·µÉR(x,Œ¥·µÉ) = mean([Œî·µÉR(x,Œ¥·µÉ,r) for r in r·µÉ(x)])
EŒî·µáR(x,Œ¥·µá) = mean([Œî·µáR(x,Œ¥·µá,r) for r in r·µá(x)])
EŒî·µÉ·µñR(x) = mean([Œî·µÉ·µñR(x,r) for r in r·µÉ(x)])
EŒî·µá·µñR(x) = mean([Œî·µá·µñR(x,r) for r in r·µá(x)])

#Infinitesimal operator for V
function AV(Œ∏,x,Œ¥·µÉ,Œ¥·µá)
    Œ∏*(ùî≠*s(x)-p(x))*‚àÇVp(Œ∏,x)
    + 0.5 * s(x)^2 *(œÇ^2 * ‚àÇ‚àÇVss(Œ∏,x) + Œ∫^2 * ‚àÇ‚àÇVpp(Œ∏,x) + 2 * œ± * œÇ * Œ∫ * ‚àÇ‚àÇVsp(Œ∏,x))
    + Œª·µÉ^-1 * EŒî·µÉV(Œ∏,x,Œ¥·µÉ) + Œª·µá^-1 * EŒî·µáV(Œ∏,x,Œ¥·µá) + Œª·µñ^-1 * EŒî·µÉ·µñV(Œ∏,x) + Œª·µñ^-1 * EŒî·µá·µñV(Œ∏,x)
end

#Infinitesimal operator for R
function AR(x,Œ¥·µÉ,Œ¥·µá)
    Parameters.Œ∏*(ùî≠*s(x)-p(x))*‚àÇRp(x)
    + 0.5 * s(x)^2 *(œÇ^2 * ‚àÇ‚àÇRss(x) + Œ∫^2 * ‚àÇ‚àÇRpp(x) + 2 * œ± * œÇ * Œ∫ * ‚àÇ‚àÇRsp(x))
    + Œª·µÉ^-1 * EŒî·µÉR(x,Œ¥·µÉ) + Œª·µá^-1 * EŒî·µáR(x,Œ¥·µá) + Œª·µñ^-1 * EŒî·µÉ·µñR(x) + Œª·µñ^-1 * EŒî·µá·µñR(x)
end

#L operator as described in the thesis
function LV(Œ∏,x,Œ¥·µÉ,Œ¥·µá)
    AR(x,Œ¥·µÉ,Œ¥·µá) + AV(Œ∏,x,Œ¥·µÉ,Œ¥·µá) - œÅ*V(Œ∏,x)
end

#Intervention function as described in the thesis
function Œì(x,Œæ)
    x .+ [-(s(x)-p(x))*Œæ - abs(Œæ)*s(x)*œá, 0, 0, 0, Œæ]
end

#Intervention operator
function MV(Œ∏,x,Œæ)
    V(Œ∏,Œì(x,Œæ))-V(Œ∏,x)
end

#Establishes valid values for Œæ depending on the position
function validŒæ(q,h)
    if q+h> hedge_limit #long
        max(-q-h,-5):0
    elseif q+h < -hedge_limit
        0:min(-q-h,5)
    else
        0:0
    end
end

#Greedy controls
maxŒ¥·µÉ(Œ∏,x) = 0.0001*argmax([EŒî·µÉV(Œ∏,x,Œ¥)+EŒî·µÉR(x,Œ¥) for Œ¥ in 0.0001:0.0001:0.0020])
maxŒ¥·µá(Œ∏,x) = 0.0001*argmax([EŒî·µáV(Œ∏,x,Œ¥)+EŒî·µáR(x,Œ¥) for Œ¥ in 0.0001:0.0001:0.0020])
maxŒæ(Œ∏,x)  = validŒæ(q(x),h(x))[argmax([V(Œ∏,Œì(x,Œæ)) for Œæ in validŒæ(q(x),h(x))])]

#[(Œ¥,round(EŒî·µÉV(last(Œ∏),x‚ÇÄ,Œ¥),digits=2),EŒî·µÉR(x‚ÇÄ,Œ¥)) for Œ¥ in 0.0001:0.0001:0.0020]
#[(Œ¥,round(EŒî·µáV(last(Œ∏),x‚ÇÄ,Œ¥),digits=2),EŒî·µáR(x‚ÇÄ,Œ¥)) for Œ¥ in 0.0001:0.0001:0.0020]
#[(Œæ,round(V(Œ∏1,Œì(x‚ÇÄ,Œæ)),digits=2)) for Œæ in validŒæ(-2000000,-2000000)]

#maxŒæ(Œ∏1,x‚ÇÄ+[0,0,0,20000,20000])

function total_reward(x‚ÇÄ;Œ∏·µõ=Œ∏·µõ,N=100,T=1,Simulations=10,Safe=true)
    Œît = 1/N
    reward = 0
    reward = @distributed (+) for i = 1:Simulations
        reward_i = 0
        sim = simulate(x‚ÇÄ;N=N,T=T)
        t=1
        x = x‚ÇÄ
        for j in sim
            bid = Safe ? min(0.01,max(0.0001,maxŒ¥·µá(Œ∏·µõ,x))) : maxŒ¥·µá(Œ∏·µõ,x)
            offer = Safe ? min(0.01,max(0.0001,maxŒ¥·µÉ(Œ∏·µõ,x))) : maxŒ¥·µÉ(Œ∏·µõ,x)
            hedge = maxŒæ(Œ∏·µõ,x)
            if isnan(hedge)
                hedge=0
            end
            if isinf(hedge)
                hedge=0
            end
            new_x = [y(x), j[1], j[2], q(x), h(x)]
            new_r·µÉ = j[3]
            new_r·µá = j[4]
            if new_r·µÉ >= offer
                new_x = new_x + [s(new_x),0,0,-1,0]
            end
            if new_r·µá >= bid
                new_x = new_x + [-s(new_x),0,0,1,0]
            end
            if offer < 0 || bid < 0
                new_x = new_x + [- s(new_x)*œá,0,0,0,0]
            end
            posicao = q(x)+h(x)
            if posicao > hedge_limit
                hedge = max(-posicao,min(0,hedge))
            elseif posicao < -hedge_limit
                hedge = min(-posicao,max(0,hedge))
            end

            if abs(hedge) >= 1
                new_x = Œì(new_x,hedge)
            end
            reward_i += exp(-œÅ*t*Œît)*R(new_x) - exp(-œÅ*(t-1)*Œît)*R(x)
            if isnan(reward_i)
                println("NAN at ",x," -> ",new_x," hedge: ",hedge,", t: ",t)
                break
            end
            x = new_x
            t+=1
        end
        #reward += reward_i
        reward_i + exp(-œÅ*t)*R(x)
    end
    reward/N
end


#Initial values for the function approximations parameters
#Œ∏·µõ = rand(length(œï(ones(5))))
Œ∏·µÉ = zeros(length(œï(ones(5))))
Œ∏·µá = zeros(length(œï(ones(5))))
Œ∏ ∑ = zeros(length(œï(ones(5))))

hjbqvi(Œ∏,x) = max(LV(Œ∏,x,maxŒ¥·µÉ(Œ∏,x),maxŒ¥·µá(Œ∏,x)),MV(Œ∏,x,maxŒæ(Œ∏,x)))
hjbqvi(Œ∏) = vcat([hjbqvi(Œ∏,x) for x in batch]...)

V_estimate(Œ∏,x) = hjbqvi(Œ∏,x) + V(Œ∏,x)
V_estimate(Œ∏) = vcat([V_estimate(Œ∏,x) for x in batch]...)

V_bar(Œ∏) = vcat([V(Œ∏,x) for x in batch]...)
maxŒ¥·µÉ(Œ∏) = mean([maxŒ¥·µÉ(Œ∏,x) for x in batch])
maxŒ¥·µá(Œ∏) = mean([maxŒ¥·µá(Œ∏,x) for x in batch])
maxŒæ(Œ∏) = mean([maxŒæ(Œ∏,x) for x in batch])

function second_order_condition(grad1,grad2)
    [grad1[i]*grad2[i] + grad1[j]*grad2[j] - abs(grad1[i]*grad2[j]+grad1[j]*grad2[i]) for i in 1:5 for j in i:5 if i!=j]
end

function third_order_condition(grad1, grad2)
    [grad1[i]*grad2[i] + grad1[j]*grad2[j] + grad1[k]*grad2[k] - abs(grad1[i]*grad2[j]+grad1[j]*grad2[i]) - abs(grad1[i]*grad2[k]+grad1[k]*grad2[i]) - abs(grad1[k]*grad2[j]+grad1[j]*grad2[k]) for i in 1:5 for j in i:5 for k in 1:5 if i<j && j<k]
end

function fourth_order_condition(grad1, grad2)
    [grad1[i]*grad2[i] + grad1[j]*grad2[j] + grad1[k]*grad2[k] + grad1[h]*grad2[h] - abs(grad1[i]*grad2[j]+grad1[j]*grad2[i]) - abs(grad1[i]*grad2[k]+grad1[k]*grad2[i]) - abs(grad1[k]*grad2[j]+grad1[j]*grad2[k]) - abs(grad1[h]*grad2[i]+grad1[i]*grad2[h]) - abs(grad1[h]*grad2[j]+grad1[j]*grad2[h]) - abs(grad1[h]*grad2[k]+grad1[k]*grad2[h]) for i in 1:5 for j in i:5 for k in 1:5 for h in 1:5 if i<j && j<k && k<h]
end

function fifth_order_condition(grad1, grad2)
    [
    grad1[1]*grad2[1] +
    grad1[2]*grad2[2] +
    grad1[3]*grad2[3] +
    grad1[4]*grad2[4] +
    grad1[5]*grad2[5]
    - abs(grad1[1]*grad2[2]+grad1[2]*grad2[1])
    - abs(grad1[1]*grad2[3]+grad1[3]*grad2[1])
    - abs(grad1[3]*grad2[2]+grad1[2]*grad2[3])
    - abs(grad1[4]*grad2[1]+grad1[1]*grad2[4])
    - abs(grad1[4]*grad2[2]+grad1[2]*grad2[4])
    - abs(grad1[4]*grad2[3]+grad1[3]*grad2[4])
    - abs(grad1[5]*grad2[1]+grad1[1]*grad2[5])
    - abs(grad1[5]*grad2[2]+grad1[2]*grad2[5])
    - abs(grad1[5]*grad2[3]+grad1[3]*grad2[5])
    - abs(grad1[5]*grad2[4]+grad1[4]*grad2[5])
    ]
end

function constraint_eigen(Œ∏,x)
  v = ‚àáVx(Œ∏,x)
  r = ‚àáR(x)
  A=[v[1]*r[1] v[1]*r[2] v[1]*r[3] v[1]*r[4] v[1]*r[5];
  v[2]*r[1] v[2]*r[2] v[2]*r[3] v[2]*r[4] v[2]*r[5];
  v[3]*r[1] v[3]*r[2] v[3]*r[3] v[3]*r[4] v[3]*r[5];
  v[4]*r[1] v[4]*r[2] v[4]*r[3] v[4]*r[4] v[4]*r[5];
  v[5]*r[1] v[5]*r[2] v[5]*r[3] v[5]*r[4] v[5]*r[5]]
  eigen(0.5*(A+A')).values
end

function constraint_eigen(z)
    Œ∏ = z[1:length(Œ∏·µõ)]
    x = z[length(Œ∏)+1:end]
    sum(constraint_eigen(Œ∏,x))
end

‚àáconstrain_eigen(Œ∏,x) = ForwardDiff.gradient(constraint_eigen,[Œ∏;x])

# function constraint(Œ∏)
#     vcat([constraint_eigen(Œ∏,x) for x in batch]...)
# end

function V_constraint1(Œ∏)
    vcat([‚àáVx(Œ∏,x) .* ‚àáR(x) for x in batch]...)
end

function V_constraint2(Œ∏)
    vcat([second_order_condition(‚àáVx(Œ∏,x),‚àáR(x)) for x in batch]...)
end

function V_constraint3(Œ∏)
    vcat([third_order_condition(‚àáVx(Œ∏,x),‚àáR(x)) for x in batch]...)
end

function V_constraint4(Œ∏)
    vcat([fourth_order_condition(‚àáVx(Œ∏,x),‚àáR(x)) for x in batch]...)
end

function V_constraint5(Œ∏)
    vcat([fifth_order_condition(‚àáVx(Œ∏,x),‚àáR(x)) for x in batch]...)
end

function constraint(Œ∏)
    [V_constraint1(Œ∏);V_constraint2(Œ∏);V_constraint3(Œ∏);V_constraint4(Œ∏);V_constraint5(Œ∏)]
end

regularization_parameter = 1e5

function objective_breakdown(z)
    Œ∏ = z[1:length(Œ∏·µõ)]
    œµ = z[length(Œ∏)+1:length(Œ∏)+41*length(batch)]
    Œª = z[length(Œ∏)+1+41*length(batch):length(Œ∏)+82*length(batch)]
    Œ∑ = z[length(Œ∏)+82*length(batch)+1]
    sum((V_estimate(Œ∏)-V_bar(Œ∏)).^2), regularization_parameter*sum(Œ∏.^2) , - Œª'*(constraint(Œ∏) - œµ.^2) , 0.5 * Œ∑ * sum((constraint(Œ∏) - œµ.^2) .^2)
end

#+ regularization_parameter*sum(Œ∏.^2)
#Lagrangian objective
function objective(z)
    Œ∏ = z[1:length(Œ∏·µõ)]
    œµ = z[length(Œ∏)+1:length(Œ∏)+41*length(batch)]
    Œª = z[length(Œ∏)+1+41*length(batch):length(Œ∏)+82*length(batch)]
    Œ∑ = z[length(Œ∏)+82*length(batch)+1]
    sum((V_estimate(Œ∏)-V_bar(Œ∏)).^2)  - Œª'*(constraint(Œ∏) - œµ.^2) + 0.5 * Œ∑ * sum((constraint(Œ∏) - œµ.^2) .^2) #0.5sum(abs.(Œ∏))
end
objective(Œ∏,œµ,Œª,Œ∑) = objective([Œ∏;œµ;Œª;Œ∑])
‚àáobjective(Œ∏,œµ,Œª,Œ∑) = ForwardDiff.gradient(objective,[Œ∏;œµ;Œª;Œ∑])[1:length(Œ∏)+41*length(batch)]

function minimize_lagrangian(Œ∏‚ÇÄ,Œª;gradient_step = 10^-10, penalty_parameter = 1, n_iter = 40, debug = false)
    F = zeros(n_iter)
    Œ∏ = [Œ∏‚ÇÄ for i in 1:n_iter]
    œµ = [zeros(length(Œª)) for i in 1:n_iter]
    improvement = [0.0 for i in 1:n_iter]
    restarted = false
    for iter = 1:n_iter
        F[iter] = objective(Œ∏[iter],œµ[iter],Œª,penalty_parameter)
        if iter>1
            if F[iter]>F[iter-1]
                gradient_step /= 4
                restarted = true
                #restart the search
                if debug
                    println(">> F[$iter] is worse than F[$(iter-1)]: $(F[iter]) > $(F[iter-1]), gradient_step was $gradient_step")
                    println(">> Restarting search")
                end
                F[iter] = F[iter-1]
                Œ∏[iter] = Œ∏[iter-1]
                #return F[iter-1],Œ∏[iter-1],œµ[iter-1],gradient_step
            elseif gradient_step < 10^-6 && !restarted
                gradient_step *= 2 #max(1,log(abs(F[iter]))/2)
            end
        end
        grad = ‚àáobjective(Œ∏[iter],œµ[iter],Œª,penalty_parameter)
        if iter<n_iter
            Œ∏[iter+1] = Œ∏[iter] - gradient_step * grad[1:length(Œ∏‚ÇÄ)]
            œµ[iter+1] = œµ[iter] - gradient_step * grad[length(Œ∏‚ÇÄ)+1:end]
        elseif iter==n_iter
            return F[iter],Œ∏[iter],œµ[iter],gradient_step
        end
        improvement[iter] = iter>1 ? max((F[iter-1]-F[iter])/abs(F[iter-1]), 0.0) : 0.0
        if improvement[iter] < 0.01 && !restarted && gradient_step < 0.1
            gradient_step *= 10
        end
        if restarted && improvement[iter] < 2e-4 && improvement[iter] < improvement[iter-1]
            return F[iter],Œ∏[iter],œµ[iter],gradient_step
        end
        if debug
            println(">> Objective F(Œ∏[$iter])): $(F[iter])", improvement[iter] > 0 ? ". Improvement: $(@sprintf("%.4f",100*improvement[iter]))%" : ". No improvemnt with gradient step $gradient_step.")
        end
    end
end

function solve_problem(Œ∏‚ÇÄ;
    n_outer_iter = 20, n_inner_iter = 20, gradient_step = 10^-10, adjoint_step=10^-5,
    penalty_parameter=1, current_epoch = 1, debug=false)
    #Lagrange multipliers
    Œª = ones(41*length(batch))
    F = zeros(n_outer_iter)
    Œ∏ = [Œ∏‚ÇÄ for i in 1:n_outer_iter]
    œµ = [ones(length(Œª)) for i in 1:n_outer_iter]
    Œ∑ = penalty_parameter
    for iter = 1:n_outer_iter
        if debug println("> Iteration $current_epoch.$iter:") end
        F[iter], Œ∏[iter], œµ[iter], gradient_step = minimize_lagrangian(Œ∏[iter],Œª;gradient_step=gradient_step,penalty_parameter=Œ∑,n_iter=n_inner_iter,debug=debug)
        Œª += adjoint_step * (constraint(Œ∏[iter]) - œµ[iter].^2)
        Œª = [max(k,0) for k in Œª]
        if debug println("> Best F[$current_epoch.$iter] = $(F[iter])") end
        if iter>1
            if F[iter] > F[iter-1]
                if debug println("> F[$current_epoch.$iter] is worse than F[$current_epoch.$(iter-1)]: $(F[iter]) > $(F[iter-1])") end
                return Œ∏[iter-1],gradient_step
            elseif iter==n_outer_iter
                return Œ∏[iter],gradient_step
            elseif adjoint_step < 0.05
                adjoint_step *= 2
            end
        end
        Œ∏[iter+1] = Œ∏[iter]
    end
end

function td0_episode(Œ∏·µõ,x‚ÇÄ;N=1000,T=1,learning_rate=0.05,safe=true)
    Œît = 1/N
    reward = 0
    path = simulate(x‚ÇÄ;N=N,T=T)
    x = x‚ÇÄ
    t = 1
    ŒîP = zeros(length(Œ∏·µõ))
    ŒîŒ∏ = zeros(length(Œ∏·µõ))
    for (s‚Çú,p‚Çú,r·µÉ,r·µá) in path
        bid = safe ? min(0.01,max(0.0001,maxŒ¥·µá(Œ∏·µõ,x))) : maxŒ¥·µá(Œ∏·µõ,x)
        offer = safe ? min(0.01,max(0.0001,maxŒ¥·µÉ(Œ∏·µõ,x))) : maxŒ¥·µÉ(Œ∏·µõ,x)
        hedge = maxŒæ(Œ∏·µõ,x)
        if isnan(hedge) || isinf(hedge)
            hedge=0
        end
        x‚Çú = [y(x), s‚Çú, p‚Çú, q(x), h(x)] .+ (r·µÉ >= offer ? [s‚Çú,0,0,-1,0] : [0,0,0,0,0]) .+ (r·µá >= bid ? [-s‚Çú,0,0,1,0] : [0,0,0,0,0])
        pos = q(x)+h(x)
        if pos > hedge_limit
            hedge = max(-pos,min(0,hedge))
        elseif pos < -hedge_limit
            hedge = min(-pos,max(0,hedge))
        end
        if abs(hedge) >= 1
            x‚Çú = Œì(x‚Çú,hedge)
        end
        reward‚Çú = exp(-œÅ*t*Œît)*R(x‚Çú) - exp(-œÅ*(t-1)*Œît)*R(x)
        reward += reward‚Çú
        ŒîP = œï(x) #‚àáVŒ∏(Œ∏·µõ,x)
        P = V(Œ∏·µõ,x)
        P‚Çú = t==length(path) ? reward + exp(-œÅ*t*Œît)*R(x‚Çú) : V(Œ∏·µõ,x‚Çú)
        ŒîŒ∏ += learning_rate * (P‚Çú - P) * ŒîP
        x = x‚Çú
        if sum(isnan.(ŒîŒ∏))> 0
            println("Found NaN. learning_rate = $learning_rate, x = $x, x‚Çú = $x‚Çú, reward‚Çú = $reward‚Çú, Œ∏·µõ = $Œ∏·µõ")
            break
        end
        t+=1
    end
    #println("Last x = $x, R(x) = $(R(x)), reward = $reward")
    Œ∏·µõ+ŒîŒ∏, reward
end


function td0_episode_online(Œ∏·µõ,x‚ÇÄ;N=1000,T=1,learning_rate=0.05,safe=true)
    Œît = 1/N
    reward = 0
    path = simulate(x‚ÇÄ;N=N,T=T)
    x = x‚ÇÄ
    t = 1
    ŒîP = zeros(length(Œ∏·µõ))
    ŒîŒ∏ = zeros(length(Œ∏·µõ))
    for (s‚Çú,p‚Çú,r·µÉ,r·µá) in path
        bid = safe ? min(0.01,max(0.0001,maxŒ¥·µá(Œ∏·µõ,x))) : maxŒ¥·µá(Œ∏·µõ,x)
        offer = safe ? min(0.01,max(0.0001,maxŒ¥·µÉ(Œ∏·µõ,x))) : maxŒ¥·µÉ(Œ∏·µõ,x)
        hedge = maxŒæ(Œ∏·µõ,x)
        if isnan(hedge) || isinf(hedge)
            hedge=0
        end
        x‚Çú = [y(x), s‚Çú, p‚Çú, q(x), h(x)] .+ (r·µÉ >= offer ? [s‚Çú,0,0,-1,0] : [0,0,0,0,0]) .+ (r·µá >= bid ? [-s‚Çú,0,0,1,0] : [0,0,0,0,0])
        pos = q(x)+h(x)
        if pos > hedge_limit
            hedge = max(-pos,min(0,hedge))
        elseif pos < -hedge_limit
            hedge = min(-pos,max(0,hedge))
        end
        if abs(hedge) >= 1
            x‚Çú = Œì(x‚Çú,hedge)
        end
        reward‚Çú = exp(-œÅ*t*Œît)*R(x‚Çú) - exp(-œÅ*(t-1)*Œît)*R(x)
        reward += reward‚Çú
        ŒîP = œï(x) #‚àáVŒ∏(Œ∏·µõ,x)
        P = V(Œ∏·µõ,x)
        P‚Çú = t==length(path) ? reward + exp(-œÅ*t*Œît)*R(x‚Çú) : V(Œ∏·µõ,x‚Çú)
        Œ∏·µõ += learning_rate * (P‚Çú - P) * ŒîP
        x = x‚Çú
        if sum(isnan.(ŒîŒ∏))> 0
            println("Found NaN. learning_rate = $learning_rate, x = $x, x‚Çú = $x‚Çú, reward‚Çú = $reward‚Çú, Œ∏·µõ = $Œ∏·µõ")
            break
        end
        t+=1
    end
    #println("Last x = $x, R(x) = $(R(x)), reward = $reward")
    Œ∏·µõ, reward
end

function td1_episode(Œ∏·µõ,x‚ÇÄ;N=1000,T=1,learning_rate=0.05,safe=true)
    Œît = 1/N
    reward = 0
    path = simulate(x‚ÇÄ;N=N,T=T)
    x = x‚ÇÄ
    t = 1
    ŒîP = zeros(length(Œ∏·µõ))
    ŒîŒ∏ = zeros(length(Œ∏·µõ))
    for (s‚Çú,p‚Çú,r·µÉ,r·µá) in path
        bid = safe ? min(0.01,max(0.0001,maxŒ¥·µá(Œ∏·µõ,x))) : maxŒ¥·µá(Œ∏·µõ,x)
        offer = safe ? min(0.01,max(0.0001,maxŒ¥·µÉ(Œ∏·µõ,x))) : maxŒ¥·µÉ(Œ∏·µõ,x)
        hedge = maxŒæ(Œ∏·µõ,x)
        if isnan(hedge) || isinf(hedge)
            hedge=0
        end
        x‚Çú = [y(x), s‚Çú, p‚Çú, q(x), h(x)] .+ (r·µÉ >= offer ? [s‚Çú,0,0,-1,0] : [0,0,0,0,0]) .+ (r·µá >= bid ? [-s‚Çú,0,0,1,0] : [0,0,0,0,0])
        pos = q(x)+h(x)
        if pos > hedge_limit
            hedge = max(-pos,min(0,hedge))
        elseif pos < -hedge_limit
            hedge = min(-pos,max(0,hedge))
        end
        if abs(hedge) >= 1
            x‚Çú = Œì(x‚Çú,hedge)
        end
        reward‚Çú = exp(-œÅ*t*Œît)*R(x‚Çú) - exp(-œÅ*(t-1)*Œît)*R(x)
        reward += reward‚Çú
        #reward‚Çú = exp(-œÅ*Œît)*R(x‚Çú) - R(x)
        #Œ∏·µõ += learning_rate * (reward‚Çú + exp(-œÅ*Œît)*V(Œ∏·µõ,x‚Çú) - V(Œ∏·µõ,x) ) * ‚àáVŒ∏(Œ∏·µõ,x)
        #reward‚Çú +
        #td_error = reward + exp(-œÅ*t*Œît)*V(Œ∏·µõ,x‚Çú) - V(Œ∏·µõ,x‚ÇÄ)
        # hjbqvi_error = hjbqvi(Œ∏·µõ,x‚Çú)
        # if !isnan(hjbqvi_error) && !isinf(hjbqvi_error) && hjbqvi_error!=0
        #     td_error = hjbqvi_error
        # end
        ŒîP += œï(x) # ‚àáVŒ∏(Œ∏·µõ,x)
        P = V(Œ∏·µõ,x)
        P‚Çú = t==length(path) ? reward + exp(-œÅ*t*Œît)*R(x‚Çú) : V(Œ∏·µõ,x‚Çú)
        ŒîŒ∏ += learning_rate * (P‚Çú - P) * ŒîP
        x = x‚Çú
        #Œ∏·µõ += learning_rate * td_error * ‚àáVŒ∏(Œ∏·µõ,x)
        #ŒîŒ∏·µõ = learning_rate * td_error * ‚àáVŒ∏(Œ∏·µõ,x)
        if sum(isnan.(ŒîŒ∏))> 0
            println("Found NaN. learning_rate = $learning_rate, x = $x, x‚Çú = $x‚Çú, reward‚Çú = $reward‚Çú, Œ∏·µõ = $Œ∏·µõ")
            break
        # else
        #     Œ∏·µõ += ŒîŒ∏·µõ
        end
        t+=1
    end
    #println("Last x = $x, R(x) = $(R(x)), reward = $reward")
    Œ∏·µõ+ŒîŒ∏, reward
end

grid_space = [[x‚ÇÄ];[[0,100,0,2000,2000]];[[0,100,0,2000,-2000]];[[0,100,0,-2000,2000]];[[0,100,0,-2000,-2000]]]
shuffle!(grid_space)

batch = [x+[cash,price,premium,0,0] for x in grid_space for cash in [-10^5, 0, 10^5] for premium in [-1, -0.5, -0.2, 0, 0.2, 0.5, 1] for price in [-1, 0, 1]]
shuffle!(batch)

#Œ∏1 = [-1.0001, 0.829139, 0.520647, 0.0970372, 0.521014, -0.134654, 0.387083, 0.115137, 0.0475305, 0.466884]
Œ∏0 = [0., 1., 0., 0., 0., 0., 0.] #last(Œ∏) #rand(7)-0.5 #[0.113619, 0.00993826, 0.0216627, 0.056741, 0.0100034, 0.00999995, 0.01] #[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
Œ∏ = [Œ∏0 for i in 1:1000]
learning_rate = [i for i in range(0.5,stop=0.25,length=length(Œ∏))]
gross_reward = 0
for iter in 1:length(Œ∏)-1
    x‚Çú=vcat(sample(batch,1)...)
    Œ∏[iter+1], reward‚Çú = td0_episode(Œ∏[iter],x‚Çú,learning_rate=learning_rate[iter]*1e-11)
    reward‚Çú = round(reward‚Çú,digits=4)
    gross_reward += reward‚Çú
    error‚ÇÄ = V(Œ∏[iter+1],x‚ÇÄ) - V(Œ∏[iter],x‚ÇÄ)
    error‚Çú = V(Œ∏[iter+1],x‚Çú) - V(Œ∏[iter],x‚Çú)
    V‚ÇÄ = round(V(Œ∏[iter+1],x‚ÇÄ),digits=4)
    V‚Çú = round(V(Œ∏[iter+1],x‚Çú),digits=4)
    R‚Çú = R(x‚Çú)
    error‚ÇÄ = round(error‚ÇÄ,digits=4)
    error‚Çú = round(error‚Çú,digits=4)
    error =round(abs(error‚ÇÄ) + abs(error‚Çú),digits=4)
    println("[$(iter+1)] V‚ÇÄ = $V‚ÇÄ, Error = ($error), Reward = $reward‚Çú, Reward avg = $(gross_reward/iter), Œ∏ = $(Œ∏[iter+1])")
end

# #The learning rates below indicate how much % we want to learn from the current best
# #and how much we want to learn from the new optimized function, given the new data
# learning_rate = 1.0
#
# grid_space = [[x‚ÇÄ+[1000,0,0,0,0]];[[0,100,0,2000,2000]];[[0,100,0,2000,-2000]];[[0,100,0,-2000,2000]];[[0,100,0,-2000,-2000]]]
#
# master_batch = grid_space #[x+[cash,price,premium,0,0] for x in grid_space for cash in [-10^5, 0, 10^5] for premium in [-1, -0.5, -0.2, 0, 0.2, 0.5, 1] for price in [-1, 0, 1]]
# #shuffle!(master_batch)
# master_batch_matrix = permutedims(Flux.batch(œï.(master_batch)))
# master_mean = [abs(mean(master_batch_matrix[:,i])) for i in 1:length(Œ∏·µõ)]
#
# batch_iter = 1
# batch = master_batch[1:1] #sample(master_batch,1) #[sample(master_batch,3,replace=false);[x‚ÇÄ]]
# V_batch =[V(Œ∏·µõ,x) for x in batch]
# œï_X = œï(batch)
# Œ∏·µõ = rand(length(œï(ones(5)))) - 0.5
# penalty_parameter = 1 #2e-7
# gradient_step = 10^-6
# Œ∏·µõhistory = [Œ∏·µõ]
# Vhistory = [V(Œ∏·µõ,x‚ÇÄ)]
#
# for iter = 1:100
#     println("Epoch: $iter")
#     current_penalty_parameter = iter <= 10 ? penalty_parameter : 0.5*penalty_parameter
#     Œ∏·µõ,gradient_step = solve_problem(Œ∏·µõ,
#         gradient_step = gradient_step,
#         adjoint_step = 0.001,
#         penalty_parameter = current_penalty_parameter,
#         n_outer_iter = iter<5 ? 10 : 5,
#         n_inner_iter = iter<5 ? 20 : 10,
#         current_epoch = iter,
#         debug = false)
#     #current_learning_rate = iter == 1 ? 1 : max(0.05,learning_rate*(1 - sqrt(iter)/4.9))
#     #global Œ∏·µõ = last(Œ∏·µõhistory)*(1-current_learning_rate) + Œ∏·µõ * current_learning_rate
#     global Œ∏·µõhistory = [Œ∏·µõhistory..., Œ∏·µõ]
#     gradient_step /= 10
#     br1, br2, br3, br4 = objective_breakdown([Œ∏·µõ;ones(41*length(batch));ones(41*length(batch));current_penalty_parameter])
#     println("Objective breakdown = [$br1, $br2, $br3, $br4], gradient step: $(gradient_step)")
#     println("V(Œ∏[$iter],x[$(batch[1])]) = ",V(Œ∏·µõ,batch[1]))#
#     global Vhistory = [Vhistory..., V(Œ∏·µõ,x‚ÇÄ)]
#     previous_V_batch = V_batch
#     V_batch = [V(Œ∏·µõ,x) for x in batch]
#     batch_objective = sum((V_batch - previous_V_batch) .^2)
#     println("Batch[$batch_iter] = $batch_objective")
#     println("Œ∏[$iter] = $Œ∏·µõ")
# end

function generate_scenario(Œ∏·µõ,f::Function, name::String, interval, should_plot)
    scenario = DataFrame()
    scenario[:q] = vcat([q for q in interval, h in interval]...)
    scenario[:h] = vcat([h for q in interval, h in interval]...)
    scenario[:bid] = vcat([maxŒ¥·µá(Œ∏·µõ,f(q,h)) for q in interval, h in interval]...)
    scenario[:offer] = vcat([maxŒ¥·µÉ(Œ∏·µõ,f(q,h)) for q in interval, h in interval]...)
    scenario[:hedge] = vcat([maxŒæ(Œ∏·µõ,f(q,h)) for q in interval, h in interval]...)
    scenario[:wealth] = vcat([v(f(q,h)) for q in interval, h in interval]...)
    scenario[:utility] = vcat([R(f(q,h)) for q in interval, h in interval]...)
    scenario[:value] = vcat([V(Œ∏·µõ,f(q,h)) for q in interval, h in interval]...)
    if should_plot
        surface(scenario[:q],scenario[:h],scenario[:bid], title="Bid - $name")
        surface(scenario[:q],scenario[:h],scenario[:offer],  title="Offer - $name")
        surface(scenario[:q],scenario[:h],scenario[:hedge],  title="Hedge - $name")
        surface(scenario[:q],scenario[:h],scenario[:wealth], title="Wealth - $name")
        surface(scenario[:q],scenario[:h],scenario[:utility], title="Utility - $name")
        surface(scenario[:q],scenario[:h],scenario[:value], title="Value - $name")
        contour(scenario[:q],scenario[:h],scenario[:value], title="Value - $name")
    end
    return scenario
end

#last(Œ∏)
#Same wealth scenario, different arrangements of position
generate_scenario(last(Œ∏),(q,h) -> x‚ÇÄ+[-100*(q+h),0,0,q,h], "Scenario 1",-2000:100:2000, true)
# #Zero cash scenarion, different arrangements of position
generate_scenario(last(Œ∏),(q,h) -> x‚ÇÄ+[0,0,0,q,h], "Scenario 2",-2000:100:2000, true)
# #Same wealth scenario, different arrangements of position
#generate_scenario(Œ∏·µõ,(q,h) -> x‚ÇÄ+[-100*(q+h),0,0,q,h], "Scenario 1",-2000:100:2000, true)
# #Zero cash scenarion, different arrangements of position
#generate_scenario(Œ∏·µõ,(q,h) -> x‚ÇÄ+[0,0,0,q,h], "Scenario 2",-2000:100:2000, true)


plot(1:length(Œ∏),[V(Œ∏[i],x‚ÇÄ) for i in 1:length(Œ∏)],title="x0")
plot(1:length(Œ∏),[V(Œ∏[i],x‚ÇÄ+[1000,0,0,0,0]) for i in 1:length(Œ∏)],title="x0 with initial cash 1k")
plot(1:length(Œ∏),[V(Œ∏[i],x‚ÇÄ+[0,0,0,2000,-2000]) for i in 1:length(Œ∏)],title="x0 with hedged position")
